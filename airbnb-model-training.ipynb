{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12262163,"sourceType":"datasetVersion","datasetId":7726922},{"sourceId":12262777,"sourceType":"datasetVersion","datasetId":7727316}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libaray and Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px \nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input,Dense, Dropout, BatchNormalization ,LeakyReLU\nfrom tensorflow.keras.optimizers import Adam ,AdamW\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:47.046518Z","iopub.execute_input":"2025-06-24T16:55:47.046810Z","iopub.status.idle":"2025-06-24T16:55:47.052532Z","shell.execute_reply.started":"2025-06-24T16:55:47.046791Z","shell.execute_reply":"2025-06-24T16:55:47.051720Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"cell_type":"code","source":"df_selected_scaled = pd.read_csv(\"/kaggle/input/airbnb-df-scaled-selected-features/airbnb_df_selected_features.csv\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:49.549760Z","iopub.execute_input":"2025-06-24T16:55:49.550637Z","iopub.status.idle":"2025-06-24T16:55:49.646197Z","shell.execute_reply.started":"2025-06-24T16:55:49.550609Z","shell.execute_reply":"2025-06-24T16:55:49.645375Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df_selected_scaled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:49.844717Z","iopub.execute_input":"2025-06-24T16:55:49.845405Z","iopub.status.idle":"2025-06-24T16:55:49.860736Z","shell.execute_reply.started":"2025-06-24T16:55:49.845382Z","shell.execute_reply":"2025-06-24T16:55:49.860051Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"       price  bathrooms  beds  guests  bedrooms  country_Argentina  \\\n0       8078          1     1       2         2                  0   \n1       4665          2     2       4         2                  0   \n2       5991          1     3       4         1                  0   \n3      11339          1     2       4         1                  0   \n4       6673          1     1       2         1                  0   \n...      ...        ...   ...     ...       ...                ...   \n11527  20311          2     4       8         4                  0   \n11528   4288          8     0       4         0                  0   \n11529  15200          0     1       2         1                  0   \n11530   9103          1     2       2         1                  0   \n11531   9909          1     2       5         1                  0   \n\n       country_Armenia  country_Australia  country_Austria  \\\n0                    0                  0                0   \n1                    0                  0                0   \n2                    0                  0                0   \n3                    0                  0                0   \n4                    0                  0                0   \n...                ...                ...              ...   \n11527                0                  0                0   \n11528                0                  0                0   \n11529                0                  0                0   \n11530                0                  0                0   \n11531                0                  0                0   \n\n       country_Azerbaijan  ...  country_Uganda  country_Ukraine  \\\n0                       0  ...               0                0   \n1                       0  ...               0                0   \n2                       0  ...               0                0   \n3                       0  ...               0                0   \n4                       0  ...               0                0   \n...                   ...  ...             ...              ...   \n11527                   0  ...               0                0   \n11528                   0  ...               0                0   \n11529                   0  ...               0                0   \n11530                   0  ...               1                0   \n11531                   0  ...               0                0   \n\n       country_United Arab Emirates  country_United Kingdom  \\\n0                                 0                       0   \n1                                 0                       0   \n2                                 0                       0   \n3                                 0                       0   \n4                                 0                       0   \n...                             ...                     ...   \n11527                             0                       0   \n11528                             0                       0   \n11529                             0                       0   \n11530                             0                       0   \n11531                             0                       0   \n\n       country_United States  country_Uruguay  country_Uzbekistan  \\\n0                          0                0                   0   \n1                          0                0                   0   \n2                          0                0                   0   \n3                          0                0                   0   \n4                          0                0                   0   \n...                      ...              ...                 ...   \n11527                      0                0                   0   \n11528                      0                0                   0   \n11529                      0                0                   0   \n11530                      0                0                   0   \n11531                      0                0                   0   \n\n       country_Vanuatu  country_Vietnam  country_Åland Islands  \n0                    0                0                      0  \n1                    0                0                      0  \n2                    0                0                      0  \n3                    0                0                      0  \n4                    0                0                      0  \n...                ...              ...                    ...  \n11527                0                0                      0  \n11528                0                0                      0  \n11529                0                0                      0  \n11530                0                0                      0  \n11531                0                0                      0  \n\n[11532 rows x 121 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>bathrooms</th>\n      <th>beds</th>\n      <th>guests</th>\n      <th>bedrooms</th>\n      <th>country_Argentina</th>\n      <th>country_Armenia</th>\n      <th>country_Australia</th>\n      <th>country_Austria</th>\n      <th>country_Azerbaijan</th>\n      <th>...</th>\n      <th>country_Uganda</th>\n      <th>country_Ukraine</th>\n      <th>country_United Arab Emirates</th>\n      <th>country_United Kingdom</th>\n      <th>country_United States</th>\n      <th>country_Uruguay</th>\n      <th>country_Uzbekistan</th>\n      <th>country_Vanuatu</th>\n      <th>country_Vietnam</th>\n      <th>country_Åland Islands</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8078</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4665</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5991</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11339</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6673</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11527</th>\n      <td>20311</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11528</th>\n      <td>4288</td>\n      <td>8</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11529</th>\n      <td>15200</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11530</th>\n      <td>9103</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11531</th>\n      <td>9909</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11532 rows × 121 columns</p>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":" To enhance feature representation, new ratio-based features such as price_per_bed, price_per_guest, bedroom_per_guest, bathroom_per_guest, and bed_bath_ratio were engineered. These derived features help capture relative value and density aspects that raw features might not fully convey. \n\nAfter handling any division-related missing values, standard feature scaling was applied to selected numerical columns to normalize their distribution. This ensures that all features contribute equally to model training, especially for distance-based or gradient-sensitive algorithms.","metadata":{}},{"cell_type":"code","source":"# Add these before train-test split\ndf_selected_scaled['price_per_bed'] = df_selected_scaled['price'] / df_selected_scaled['beds'].replace(0, np.nan)\ndf_selected_scaled['price_per_guest'] = df_selected_scaled['price'] / df_selected_scaled['guests'].replace(0, np.nan)\ndf_selected_scaled['bedroom_per_guest'] = df_selected_scaled['bedrooms'] / df_selected_scaled['guests'].replace(0, np.nan)\ndf_selected_scaled['bathroom_per_guest'] = df_selected_scaled['bathrooms'] / df_selected_scaled['guests'].replace(0, np.nan)\ndf_selected_scaled['bed_bath_ratio'] = df_selected_scaled['beds'] / df_selected_scaled['bathrooms'].replace(0, np.nan)\ndf_selected_scaled = df_selected_scaled.fillna(0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:52.009599Z","iopub.execute_input":"2025-06-24T16:55:52.010362Z","iopub.status.idle":"2025-06-24T16:55:52.022834Z","shell.execute_reply.started":"2025-06-24T16:55:52.010312Z","shell.execute_reply":"2025-06-24T16:55:52.022172Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Copy the encoded dataset\ndf_scaled = df_selected_scaled.copy()\n\n#Identify numeric columns to scale (excluding target 'price')\nnumerical_cols = ['bathrooms', 'beds', 'guests', 'bedrooms']\n\n# Initialize scaler\nscaler = StandardScaler()\n\n# Fit and transform numerical features\ndf_scaled[numerical_cols] = scaler.fit_transform(df_scaled[numerical_cols])\n\n#check scaled values (mean should be ~0, std ~1)\nprint(df_scaled[numerical_cols].describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:53.247038Z","iopub.execute_input":"2025-06-24T16:55:53.247277Z","iopub.status.idle":"2025-06-24T16:55:53.273961Z","shell.execute_reply.started":"2025-06-24T16:55:53.247261Z","shell.execute_reply":"2025-06-24T16:55:53.273399Z"}},"outputs":[{"name":"stdout","text":"          bathrooms          beds        guests      bedrooms\ncount  1.153200e+04  1.153200e+04  1.153200e+04  1.153200e+04\nmean   2.218135e-17 -2.218135e-17 -6.407947e-17  1.725216e-17\nstd    1.000043e+00  1.000043e+00  1.000043e+00  1.000043e+00\nmin   -9.742699e-01 -8.331654e-01 -1.105576e+00 -9.310629e-01\n25%   -3.576244e-01 -5.465457e-01 -8.054322e-01 -4.209908e-01\n50%   -3.576244e-01 -2.599261e-01 -2.051450e-01 -4.209908e-01\n75%    2.590210e-01  2.669350e-02  3.951423e-01  8.908126e-02\nmax    2.985800e+01  2.725556e+01  3.396578e+00  2.457254e+01\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"# Spliting the Dataset","metadata":{}},{"cell_type":"code","source":"# Define features and target\nX = df_scaled.drop('price', axis=1)\ny = df_scaled['price']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:54.796941Z","iopub.execute_input":"2025-06-24T16:55:54.797621Z","iopub.status.idle":"2025-06-24T16:55:54.806030Z","shell.execute_reply.started":"2025-06-24T16:55:54.797599Z","shell.execute_reply":"2025-06-24T16:55:54.805299Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Split into train and test sets (80-20)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:55.930269Z","iopub.execute_input":"2025-06-24T16:55:55.930524Z","iopub.status.idle":"2025-06-24T16:55:55.943213Z","shell.execute_reply.started":"2025-06-24T16:55:55.930507Z","shell.execute_reply":"2025-06-24T16:55:55.942468Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"print(\"Train shape:\", X_train.shape)\nprint(\"Test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:56.197735Z","iopub.execute_input":"2025-06-24T16:55:56.198008Z","iopub.status.idle":"2025-06-24T16:55:56.202141Z","shell.execute_reply.started":"2025-06-24T16:55:56.197989Z","shell.execute_reply":"2025-06-24T16:55:56.201391Z"}},"outputs":[{"name":"stdout","text":"Train shape: (9225, 125)\nTest shape: (2307, 125)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"# **Step 3: Model Creation:**\n#  Custom ANN","metadata":{}},{"cell_type":"code","source":"def build_ann_model(input_dim):\n    model = Sequential()\n\n    model.add(Dense(512, kernel_initializer='he_normal', input_dim=input_dim))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(256, kernel_initializer='he_normal'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Dense(128, kernel_initializer='he_normal'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.3))\n\n    model.add(Dense(64, kernel_initializer='he_normal'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(1))  # Regression output\n\n    optimizer = AdamW(learning_rate=0.002, weight_decay=1e-4)\n\n    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:57.924145Z","iopub.execute_input":"2025-06-24T16:55:57.924473Z","iopub.status.idle":"2025-06-24T16:55:57.930825Z","shell.execute_reply.started":"2025-06-24T16:55:57.924449Z","shell.execute_reply":"2025-06-24T16:55:57.930067Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# K-Fold Cross-Validation","metadata":{}},{"cell_type":"code","source":"# Set up K-Fold Cross Validation\nkf = KFold(n_splits=10, shuffle=True, random_state=42)\nmse_scores = []\nmae_scores = []\n\nmse_scores_rf = []\nmae_scores_rf = []\n\nmse_scores_xgb = []\nmae_scores_xgb = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:55:59.953462Z","iopub.execute_input":"2025-06-24T16:55:59.954121Z","iopub.status.idle":"2025-06-24T16:55:59.957812Z","shell.execute_reply.started":"2025-06-24T16:55:59.954099Z","shell.execute_reply":"2025-06-24T16:55:59.957071Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# ANN Model Training And Evaluating","metadata":{}},{"cell_type":"markdown","source":"So here we build A custom Artificial Neural Network (ANN) designed for Airbnb price prediction, using multiple dense layers with LeakyReLU activation, batch normalization, and dropout for regularization. \n\nThe AdamW optimizer was used with a specified learning rate and weight decay to improve convergence. To ensure robust performance evaluation, 10-fold cross-validation was applied. \n\nEarly stopping and learning rate reduction callbacks were used during training to prevent overfitting and optimize training efficiency. \n\nMean Squared Error (MSE) and Mean Absolute Error (MAE) were calculated for each fold to assess the model’s performance.","metadata":{}},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\nFold {fold + 1}\")\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    model = build_ann_model(input_dim=X.shape[1])\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,\n                                  verbose=1, min_lr=1e-6)\n\n    model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        epochs=200,\n        batch_size=64,\n        callbacks=[early_stop, reduce_lr],\n        verbose=0\n    )\n\n    y_pred = model.predict(X_val, verbose=0)\n    mse = mean_squared_error(y_val, y_pred)\n    mae = mean_absolute_error(y_val, y_pred)\n\n    print(f\"Fold {fold + 1}: MSE = {mse:.2f}, MAE = {mae:.2f}\")\n    mse_scores.append(mse)\n    mae_scores.append(mae)\n\nprint(\"\\nFinal ANN Performance:\")\nprint(f\"Average MSE: {np.mean(mse_scores):.2f}\")\nprint(f\"Average MAE: {np.mean(mae_scores):.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T15:43:47.359646Z","iopub.execute_input":"2025-06-24T15:43:47.359946Z","iopub.status.idle":"2025-06-24T16:01:20.614242Z","shell.execute_reply.started":"2025-06-24T15:43:47.359927Z","shell.execute_reply":"2025-06-24T16:01:20.613435Z"}},"outputs":[{"name":"stdout","text":"\nFold 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 29: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 76: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 101: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 128: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 146: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 169: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 179: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 196: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\nFold 1: MSE = 1586498.30, MAE = 585.41\n\nFold 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 126: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 145: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 173: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 183: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\nEpoch 193: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\nFold 2: MSE = 1074704.44, MAE = 558.12\n\nFold 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 78: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 107: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 120: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 133: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 143: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 155: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\nEpoch 165: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\nEpoch 175: ReduceLROnPlateau reducing learning rate to 1e-06.\nFold 3: MSE = 1201139.57, MAE = 592.16\n\nFold 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 99: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 122: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 160: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 171: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 181: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 191: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\nFold 4: MSE = 971196.27, MAE = 571.18\n\nFold 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 23: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 79: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 115: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 148: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 165: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 175: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 185: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\nFold 5: MSE = 833285.46, MAE = 519.92\n\nFold 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 26: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 96: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 131: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 167: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\nFold 6: MSE = 914174.54, MAE = 532.26\n\nFold 7\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 31: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 73: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 96: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 127: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 183: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\nFold 7: MSE = 1002378.13, MAE = 508.39\n\nFold 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 28: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 86: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 114: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 137: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 149: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 159: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 169: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\nFold 8: MSE = 998776.87, MAE = 524.05\n\nFold 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 34: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 69: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 84: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 103: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 121: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 131: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 168: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 178: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\nEpoch 190: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\nEpoch 200: ReduceLROnPlateau reducing learning rate to 1e-06.\nFold 9: MSE = 1085119.39, MAE = 547.40\n\nFold 10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n\nEpoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 104: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 134: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 160: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 186: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\nFold 10: MSE = 846769.35, MAE = 519.84\n\n📊 Final ANN Performance:\nAverage MSE: 1051404.23\nAverage MAE: 545.87\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# ANN Cross-Validation Performance","metadata":{}},{"cell_type":"code","source":"# Use the unlogged version\noriginal_price = df_scaled['price']\nprint(f\"Average price: {original_price.mean():.2f}\")\nprint(f\"Median price: {original_price.median():.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T04:05:08.343308Z","iopub.execute_input":"2025-06-24T04:05:08.343625Z","iopub.status.idle":"2025-06-24T04:05:08.349391Z","shell.execute_reply.started":"2025-06-24T04:05:08.343602Z","shell.execute_reply":"2025-06-24T04:05:08.348346Z"}},"outputs":[{"name":"stdout","text":"Average price: 9274.60\nMedian price: 7248.50\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"markdown","source":"We considered A Random Forest Regressor that is optimized using RandomizedSearchCV to find the best combination of hyperparameters, such as the number of trees, maximum depth, and minimum sample requirements.","metadata":{}},{"cell_type":"code","source":"param_dist = {\n    'n_estimators': [150, 200, 250, 300, 350],\n    'max_depth': [10, 15, 20, 25, None],\n    'min_samples_split': [2, 4, 6, 10],\n    'min_samples_leaf': [1, 2, 3, 4],\n    'max_features': ['auto', 'sqrt']\n}\n\n# Create base model\nrf = RandomForestRegressor(random_state=42)\n\n# RandomizedSearchCV\nrandom_search = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=param_dist,\n    n_iter=30,\n    cv=5,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1,\n    scoring='neg_mean_absolute_error'\n)\n\n# Fit model\nrandom_search.fit(X, y)\n\n# Best parameters\nprint(\"Best parameters:\", random_search.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:56:18.157358Z","iopub.execute_input":"2025-06-24T16:56:18.157652Z","iopub.status.idle":"2025-06-24T17:02:01.294144Z","shell.execute_reply.started":"2025-06-24T16:56:18.157632Z","shell.execute_reply":"2025-06-24T17:02:01.293400Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 30 candidates, totalling 150 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters: {'n_estimators': 250, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20}\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"The search here was performed with 5-fold cross-validation, using negative MAE as the scoring metric. \n\nOnce the optimal parameters were selected, the model is now for training and evaluating using 10-fold cross-validation. \n\nMean Squared Error (MSE) and Mean Absolute Error (MAE) were calculated for each fold to assess the model’s accuracy and generalization performance.","metadata":{}},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    model = RandomForestRegressor(**random_search.best_params_, random_state=42, n_jobs=-1)\n    model.fit(X_tr, y_tr)\n\n    y_pred_rf1 = model.predict(X_val)\n    mse = mean_squared_error(y_val, y_pred_rf1)\n    mae = mean_absolute_error(y_val, y_pred_rf1)\n\n    print(f\"Fold {fold + 1}: MSE = {mse:.2f}, MAE = {mae:.2f}\")\n    mse_scores_rf.append(mse)\n    mae_scores_rf.append(mae)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:02:01.295188Z","iopub.execute_input":"2025-06-24T17:02:01.295430Z","iopub.status.idle":"2025-06-24T17:02:51.186229Z","shell.execute_reply.started":"2025-06-24T17:02:01.295412Z","shell.execute_reply":"2025-06-24T17:02:51.185509Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1: MSE = 28504.80, MAE = 45.70\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2: MSE = 18607.96, MAE = 40.55\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 3: MSE = 9735.00, MAE = 33.59\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 4: MSE = 35387.17, MAE = 48.21\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 5: MSE = 35121.55, MAE = 45.25\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 6: MSE = 12561.66, MAE = 34.95\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 7: MSE = 23623.16, MAE = 42.98\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 8: MSE = 83897.44, MAE = 43.69\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 9: MSE = 26342.37, MAE = 41.60\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 10: MSE = 13469.43, MAE = 34.64\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"print(\"\\nRandom Forest Final Performance:\")\nprint(f\"Average MSE: {np.mean(mse_scores_rf):.2f}\")\nprint(f\"Average MAE: {np.mean(mae_scores_rf):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:02:51.187040Z","iopub.execute_input":"2025-06-24T17:02:51.187368Z","iopub.status.idle":"2025-06-24T17:02:51.192300Z","shell.execute_reply.started":"2025-06-24T17:02:51.187322Z","shell.execute_reply":"2025-06-24T17:02:51.191510Z"}},"outputs":[{"name":"stdout","text":"\nRandom Forest Final Performance:\nAverage MSE: 28725.05\nAverage MAE: 41.12\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"To evaluate model performance more concretely, a comparison DataFrame was created displaying actual vs. predicted prices from the validation set. \n\nThis allows for a direct, side-by-side assessment of how closely the model's predictions align with real values. The top 20 rows were shown to visually inspect prediction accuracy.","metadata":{}},{"cell_type":"code","source":"# Create DataFrame with actual and predicted prices\ncomparison_df = pd.DataFrame({\n    'Actual Price': y_val.values.flatten(),\n    'Predicted Price': y_pred_rf1.flatten()\n})\n\n# Show top 20\ncomparison_df.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:04:19.357543Z","iopub.execute_input":"2025-06-24T17:04:19.358344Z","iopub.status.idle":"2025-06-24T17:04:19.367018Z","shell.execute_reply.started":"2025-06-24T17:04:19.358299Z","shell.execute_reply":"2025-06-24T17:04:19.366207Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"    Actual Price  Predicted Price\n0           6673      6666.261632\n1          14729     14659.285819\n2          30486     30005.804648\n3           9028      9027.385128\n4           6181      6172.255448\n5           2740      2717.308576\n6           5409      5448.799326\n7           6505      6504.942295\n8           5640      5629.030219\n9           6165      6170.567657\n10         22259     22230.317875\n11          5559      5561.177119\n12         10386     10248.553171\n13         10035     10002.144610\n14          9103      9100.889538\n15          9827      9826.705129\n16          9507      9508.821583\n17          8195      8191.342479\n18         10778     10780.472638\n19          4786      4791.057429","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Price</th>\n      <th>Predicted Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6673</td>\n      <td>6666.261632</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14729</td>\n      <td>14659.285819</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30486</td>\n      <td>30005.804648</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9028</td>\n      <td>9027.385128</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6181</td>\n      <td>6172.255448</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2740</td>\n      <td>2717.308576</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5409</td>\n      <td>5448.799326</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6505</td>\n      <td>6504.942295</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5640</td>\n      <td>5629.030219</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6165</td>\n      <td>6170.567657</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22259</td>\n      <td>22230.317875</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5559</td>\n      <td>5561.177119</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10386</td>\n      <td>10248.553171</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>10035</td>\n      <td>10002.144610</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9103</td>\n      <td>9100.889538</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>9827</td>\n      <td>9826.705129</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9507</td>\n      <td>9508.821583</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8195</td>\n      <td>8191.342479</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10778</td>\n      <td>10780.472638</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4786</td>\n      <td>4791.057429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"markdown","source":"# XGBoost Model","metadata":{}},{"cell_type":"markdown","source":"An XGBoost Regressor is built with carefully tuned hyperparameters to improve predictive accuracy and control overfitting.\nThe model is evaluated using 10-fold cross-validation to ensure reliable performance across different subsets of the data. ","metadata":{}},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\nFold {fold + 1}\")\n    \n    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]  \n\n    xgb = XGBRegressor(\n        n_estimators=314,              \n        learning_rate=0.07,            \n        max_depth=9,\n        subsample=0.94,\n        colsample_bytree=0.97,\n        gamma=0.26,\n        reg_alpha=0.15,\n        reg_lambda=1.46,\n        random_state=42,\n        n_jobs=-1\n    )\n    xgb.fit(X_tr, y_tr)\n\n    # Predict and evaluate\n    y_pred_xgb1 = xgb.predict(X_val)\n    mse = mean_squared_error(y_val, y_pred_xgb1)\n    mae = mean_absolute_error(y_val, y_pred_xgb1)\n\n    print(f\"Fold {fold + 1}: MSE = {mse:.2f}, MAE = {mae:.2f}\")\n    mse_scores_xgb.append(mse)\n    mae_scores_xgb.append(mae)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:05:38.128412Z","iopub.execute_input":"2025-06-24T17:05:38.129092Z","iopub.status.idle":"2025-06-24T17:05:50.774946Z","shell.execute_reply.started":"2025-06-24T17:05:38.129069Z","shell.execute_reply":"2025-06-24T17:05:50.774289Z"}},"outputs":[{"name":"stdout","text":"\nFold 1\nFold 1: MSE = 111196.60, MAE = 102.83\n\nFold 2\nFold 2: MSE = 37323.79, MAE = 80.22\n\nFold 3\nFold 3: MSE = 58822.49, MAE = 92.77\n\nFold 4\nFold 4: MSE = 87108.24, MAE = 95.22\n\nFold 5\nFold 5: MSE = 49053.64, MAE = 91.24\n\nFold 6\nFold 6: MSE = 41390.31, MAE = 79.62\n\nFold 7\nFold 7: MSE = 66331.76, MAE = 89.67\n\nFold 8\nFold 8: MSE = 72919.74, MAE = 85.72\n\nFold 9\nFold 9: MSE = 79513.33, MAE = 93.47\n\nFold 10\nFold 10: MSE = 37971.45, MAE = 77.55\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"So, In each fold, the model was trained on 90% of the data and validated on the remaining 10%. \n\nPerformance was assessed using Mean Squared Error (MSE) and Mean Absolute Error (MAE), with average scores reported to summarize the model’s overall effectiveness in predicting Airbnb listing prices.","metadata":{}},{"cell_type":"code","source":"# Final average performance\nprint(\"\\nXGBoost Cross-Validation Performance:\")\nprint(f\"Average MSE: {np.mean(mse_scores_xgb):.2f}\")\nprint(f\"Average MAE: {np.mean(mae_scores_xgb):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:05:50.775981Z","iopub.execute_input":"2025-06-24T17:05:50.776209Z","iopub.status.idle":"2025-06-24T17:05:50.781930Z","shell.execute_reply.started":"2025-06-24T17:05:50.776192Z","shell.execute_reply":"2025-06-24T17:05:50.780851Z"}},"outputs":[{"name":"stdout","text":"\nXGBoost Cross-Validation Performance:\nAverage MSE: 64163.13\nAverage MAE: 88.83\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Create DataFrame with actual and predicted prices\ncomparison_df = pd.DataFrame({\n    'Actual Price': y_val.values.flatten(),\n    'Predicted Price': y_pred_xgb1.flatten()\n})\n\n# Show top 20\ncomparison_df.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:06:37.403029Z","iopub.execute_input":"2025-06-24T17:06:37.403670Z","iopub.status.idle":"2025-06-24T17:06:37.412554Z","shell.execute_reply.started":"2025-06-24T17:06:37.403650Z","shell.execute_reply":"2025-06-24T17:06:37.411863Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"    Actual Price  Predicted Price\n0           6673      6651.904297\n1          14729     14914.351562\n2          30486     30616.869141\n3           9028      9014.174805\n4           6181      6247.502930\n5           2740      2777.513184\n6           5409      5380.056152\n7           6505      6491.900391\n8           5640      5747.643555\n9           6165      6182.474609\n10         22259     21982.111328\n11          5559      5536.833008\n12         10386     10303.192383\n13         10035     10095.830078\n14          9103      9066.944336\n15          9827      9812.926758\n16          9507      9459.135742\n17          8195      8163.770996\n18         10778     10745.612305\n19          4786      4743.581055","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Price</th>\n      <th>Predicted Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6673</td>\n      <td>6651.904297</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14729</td>\n      <td>14914.351562</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30486</td>\n      <td>30616.869141</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9028</td>\n      <td>9014.174805</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6181</td>\n      <td>6247.502930</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2740</td>\n      <td>2777.513184</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5409</td>\n      <td>5380.056152</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6505</td>\n      <td>6491.900391</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5640</td>\n      <td>5747.643555</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6165</td>\n      <td>6182.474609</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22259</td>\n      <td>21982.111328</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5559</td>\n      <td>5536.833008</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10386</td>\n      <td>10303.192383</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>10035</td>\n      <td>10095.830078</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9103</td>\n      <td>9066.944336</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>9827</td>\n      <td>9812.926758</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9507</td>\n      <td>9459.135742</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8195</td>\n      <td>8163.770996</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10778</td>\n      <td>10745.612305</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4786</td>\n      <td>4743.581055</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=  11.4s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=250; total time=  16.9s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.4s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=300; total time=  18.0s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=  10.4s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.9s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=  13.1s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   9.5s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=  10.6s\n[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   2.4s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=150; total time=   7.7s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=   2.3s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   1.7s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   1.8s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=250; total time=  12.9s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=250; total time=  17.5s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=250; total time=  17.7s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=350; total time=   5.0s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=250; total time=  13.9s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=250; total time=  14.0s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=  12.0s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  17.1s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=350; total time=  21.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250; total time=   2.7s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250; total time=   2.8s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250; total time=   2.8s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250; total time=   2.8s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.3s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   9.0s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=150; total time=   7.8s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=150; total time=   7.8s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250; total time=   2.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   3.4s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   3.2s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=  11.3s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=  11.1s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=250; total time=  17.2s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.4s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=300; total time=  18.6s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=  10.2s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=  10.8s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=  13.3s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   9.5s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   2.9s\n[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   2.4s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=150; total time=   7.6s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=   2.3s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=   2.2s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   1.7s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   1.7s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=250; total time=  13.1s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=250; total time=  18.0s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   8.2s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   9.1s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=350; total time=   4.9s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=250; total time=  13.8s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=  12.9s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  16.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=350; total time=  21.6s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=350; total time=  21.1s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.4s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   9.1s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=150; total time=   7.8s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   1.8s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250; total time=   2.8s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250; total time=   3.1s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   3.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=  11.5s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=250; total time=  17.1s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.2s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  15.8s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=300; total time=  18.1s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=  10.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.3s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=  13.2s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=  13.3s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   3.0s\n[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   2.4s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=150; total time=   7.7s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=   2.3s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=   2.2s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   1.8s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=250; total time=  12.8s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=250; total time=  13.2s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=250; total time=  17.3s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   8.9s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=350; total time=   5.1s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=250; total time=  14.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=  12.6s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=  11.9s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  17.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=350; total time=  21.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250; total time=   2.8s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.3s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.1s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   9.1s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=150; total time=   7.8s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   1.8s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   1.8s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250; total time=   2.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   3.3s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   2.6s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   2.2s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=  11.5s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=250; total time=  16.8s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=250; total time=  16.5s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=300; total time=  18.2s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=300; total time=  17.9s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=  11.0s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=  13.3s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   9.4s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   9.8s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=150; total time=   7.7s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=150; total time=   7.7s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=250; total time=  12.8s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=250; total time=  17.7s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   8.3s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   8.4s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=350; total time=   5.1s\n[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=350; total time=   5.0s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=10, n_estimators=250; total time=  14.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=150; total time=   1.9s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=200; total time=  12.6s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  17.0s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  17.6s\n[CV] END max_depth=25, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=350; total time=  21.0s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.8s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   9.0s\n[CV] END max_depth=20, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=150; total time=   8.9s\n[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=150; total time=   8.1s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250; total time=   2.9s\n[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   3.5s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   2.7s\n[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=150; total time=   2.1s\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"# **4.4Ensemble Methods**\n**Combined Model** ","metadata":{}},{"cell_type":"code","source":"# Loop over K-Folds\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\nFold {fold + 1}\")\n\n    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    # === Train ANN ===\n    ann = build_ann_model(input_dim=X.shape[1])\n    early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, min_lr=1e-6)\n    ann.fit(X_train, y_train, validation_data=(X_val, y_val),\n            epochs=200, batch_size=64, callbacks=[early_stop, reduce_lr], verbose=0)\n    y_pred_ann = ann.predict(X_val, verbose=0).flatten()\n\n    # === Train Random Forest ===\n    rf = RandomForestRegressor(n_estimators=250, max_depth=15, random_state=42)\n    rf.fit(X_train, y_train)\n    y_pred_rf = rf.predict(X_val)\n\n    # === Train XGBoost ===\n    xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=8, random_state=42)\n    xgb.fit(X_train, y_train)\n    y_pred_xgb = xgb.predict(X_val)\n\n    # === Ensemble: Average predictions ===\n    y_pred_ensemble = (y_pred_ann + y_pred_rf + y_pred_xgb) / 3\n\n    mse = mean_squared_error(y_val, y_pred_ensemble)\n    mae = mean_absolute_error(y_val, y_pred_ensemble)\n\n    print(f\"Fold {fold + 1} 📊 MSE: {mse:.2f}, MAE: {mae:.2f}\")\n    mse_scores.append(mse)\n    mae_scores.append(mae)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:09:16.698683Z","iopub.execute_input":"2025-06-24T16:09:16.699379Z","iopub.status.idle":"2025-06-24T16:28:45.958921Z","shell.execute_reply.started":"2025-06-24T16:09:16.699354Z","shell.execute_reply":"2025-06-24T16:28:45.958292Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nFold 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 📊 MSE: 250210.37, MAE: 213.68\n\nFold 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 📊 MSE: 135724.30, MAE: 183.50\n\nFold 3\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 3 📊 MSE: 168761.29, MAE: 225.62\n\nFold 4\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 4 📊 MSE: 166210.60, MAE: 233.35\n\nFold 5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 5 📊 MSE: 129196.28, MAE: 190.40\n\nFold 6\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 6 📊 MSE: 114268.72, MAE: 188.80\n\nFold 7\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 7 📊 MSE: 109891.54, MAE: 168.59\n\nFold 8\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 8 📊 MSE: 147777.67, MAE: 174.84\n\nFold 9\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 9 📊 MSE: 124276.00, MAE: 181.64\n\nFold 10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 10 📊 MSE: 117032.53, MAE: 182.86\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# === Final Evaluation ===\nprint(\"\\nEnsemble Performance Summary:\")\nprint(f\"Average MSE: {np.mean(mse_scores):.2f}\")\nprint(f\"Average MAE: {np.mean(mae_scores):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T16:29:14.600841Z","iopub.execute_input":"2025-06-24T16:29:14.601556Z","iopub.status.idle":"2025-06-24T16:29:14.605889Z","shell.execute_reply.started":"2025-06-24T16:29:14.601535Z","shell.execute_reply":"2025-06-24T16:29:14.605191Z"}},"outputs":[{"name":"stdout","text":"\nEnsemble Performance Summary:\nAverage MSE: 146334.93\nAverage MAE: 194.33\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Create DataFrame with actual and predicted prices\ncomparison_df = pd.DataFrame({\n    'Actual Price': y_val.values.flatten(),\n    'Predicted Price': y_pred_ensemble.flatten()\n})\n\n# Show top 20\ncomparison_df.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:07:36.034667Z","iopub.execute_input":"2025-06-24T17:07:36.034949Z","iopub.status.idle":"2025-06-24T17:07:36.044053Z","shell.execute_reply.started":"2025-06-24T17:07:36.034930Z","shell.execute_reply":"2025-06-24T17:07:36.043442Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"    Actual Price  Predicted Price\n0           6673      6732.985805\n1          14729     14841.883430\n2          30486     28967.393778\n3           9028      8983.167637\n4           6181      6207.954385\n5           2740      2512.275627\n6           5409      5393.661038\n7           6505      6586.585310\n8           5640      5645.245260\n9           6165      6175.109374\n10         22259     21997.052318\n11          5559      5569.826247\n12         10386     10074.204573\n13         10035     10042.402638\n14          9103      9179.822178\n15          9827      9804.222350\n16          9507      9478.235273\n17          8195      8277.891280\n18         10778     10709.656202\n19          4786      4709.634023","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Price</th>\n      <th>Predicted Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6673</td>\n      <td>6732.985805</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14729</td>\n      <td>14841.883430</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30486</td>\n      <td>28967.393778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9028</td>\n      <td>8983.167637</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6181</td>\n      <td>6207.954385</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2740</td>\n      <td>2512.275627</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5409</td>\n      <td>5393.661038</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6505</td>\n      <td>6586.585310</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5640</td>\n      <td>5645.245260</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6165</td>\n      <td>6175.109374</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22259</td>\n      <td>21997.052318</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5559</td>\n      <td>5569.826247</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10386</td>\n      <td>10074.204573</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>10035</td>\n      <td>10042.402638</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9103</td>\n      <td>9179.822178</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>9827</td>\n      <td>9804.222350</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>9507</td>\n      <td>9478.235273</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8195</td>\n      <td>8277.891280</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>10778</td>\n      <td>10709.656202</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4786</td>\n      <td>4709.634023</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":67},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"Among the three models, Random Forest achieved the best performance with the lowest MAE (~ 41), indicating highly accurate predictions.\nXGBoost followed closely with a moderate MAE (~ 88) and good generalization across folds.\nThe custom ANN model, while performing consistently, had a higher MAE ( ~ 546), suggesting room for further tuning or feature enhancement.\nand the combined MAE is 194.33\n\n\nOverall, tree-based models (especially Random Forest) proved more effective for this Airbnb price prediction task.","metadata":{}}]}